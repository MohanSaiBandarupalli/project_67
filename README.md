# ğŸ¬ Neural Taste Graph (NTG)
### A Production Scienceâ€“Style Machine Learning Platform for Personalization, Retention & Decision Intelligence

---

##  Executive Summary

**Neural Taste Graph (NTG)** is an end-to-end, production-inspired machine learning system designed to demonstrate **FAANG / Netflix-level ML engineering rigor**.

Unlike typical recommender demos, NTG is built as a **decision-support platform**, reflecting how ML is actually used inside organizations like Netflixâ€”to inform **personalization, retention, experimentation, and financial planning**.

The system emphasizes:
- Leakage-safe data pipelines
- Scalable analytics (DuckDB + Parquet)
- Interpretable representations before complex models
- Reproducibility, observability, and evaluation
- End-to-end ownership from raw data to decision artifacts

---

##  Problem Framing (Production Science Perspective)

Most ML projects ask:
> *â€œHow do we build the best model?â€*

NTG asks:
> *â€œHow do we design ML systems whose outputs decision-makers can trust?â€*

This framing mirrors **Production Science teams**, where:
- ML augments human decisions
- Offline correctness matters more than optimistic metrics
- Evaluation, calibration, and interpretability are first-class concerns



##  What NTG Does (End-to-End)

NTG builds an **offline ML decision pipeline** that transforms raw interaction data into:

- Personalized ranking scores
- User taste representations
- Churn risk probabilities
- Revenue / retention risk signals
- Evaluation & calibration reports

These outputs are structured to plug into:
- Experimentation frameworks
- Analyst workflows
- Planning and prioritization processes

---

##  System Architecture

### High-Level Pipeline
```text
Raw Interaction Events
        â”‚
        â–¼
DuckDB Ingestion
(SQL + Parquet, scalable analytics)
        â”‚
        â–¼
Chronological Train / Validation / Test Splits
(Leakage-safe by construction)
        â”‚
        â”œâ”€â”€â–º Feature Engineering
        â”‚        â€¢ User aggregates
        â”‚        â€¢ Recency & frequency signals
        â”‚        â€¢ Item statistics
        â”‚
        â”œâ”€â”€â–º Itemâ€“Item Similarity Graph
        â”‚        â€¢ Co-occurrence modeling
        â”‚        â€¢ Scale guardrails (power-user caps, top-K pruning)
        â”‚
        â”œâ”€â”€â–º Taste Representation
        â”‚        â€¢ Interpretable taste axes
        â”‚        â€¢ Optional latent embeddings
        â”‚
        â”œâ”€â”€â–º Personalized Ranking
        â”‚
        â”œâ”€â”€â–º Churn Risk Modeling
        â”‚
        â–¼
Decision Artifacts
        â€¢ Ranked content candidates
        â€¢ Churn probabilities
        â€¢ Calibration curves & metrics

```



flowchart TD
    A[Raw Interaction Events] --> B[DuckDB Ingestion]
    B --> C[Chronological Splits<br/>(Leakage-Safe)]
    C --> D[Feature Engineering]
    D --> E[Item-Item Similarity Graph]
    E --> F[Taste Representation]
    F --> G[Personalized Ranking]
    G --> H[Churn Risk Modeling]
    H --> I[Decision Artifacts]



##  Leakage Safety (Critical Design Principle)

All modeling decisions in NTG enforce **strict temporal correctness**:

- Chronological splits are performed once and reused everywhere
- **Only TRAIN data** is used to:
  - Build features
  - Construct graphs
  - Learn embeddings
  - Define churn labels
- Validation and test data are **never** used for feature generation

This mirrors real Production Science review standards.

---

##  Key Components

### 1ï¸ Data Ingestion & Splitting
- DuckDB used as the analytical engine
- Parquet as the storage format
- Deterministic, time-aware splits
- Scales beyond pandas-only workflows

**Location**
src/ntg/pipelines/build_dataset_duckdb.py
data/processed/splits/


---

### 2ï¸ Feature Engineering
- User-level aggregates (activity, recency, variance)
- Item-level statistics
- Interaction-level signals
- Feature manifest with metadata

**Location**
src/ntg/features/
data/features/




### 3ï¸ Itemâ€“Item Similarity Graph
- Co-occurrence-based similarity
- Power-user guardrails
- Top-K pruning to avoid quadratic blowups

**Location**
src/ntg/graph/
outputs/graph/




### 4ï¸ Taste Representation
- Interpretable â€œtaste axesâ€ derived from behavior
- Optional latent embeddings (SVD-based)
- Designed for explainability before complexity

**Location**
src/ntg/features/taste_axes.py
src/ntg/embeddings/
outputs/embeddings/




### 5ï¸ Personalized Ranking
- Candidate scoring using learned representations
- Deterministic outputs
- Designed for offline evaluation & experimentation

**Location**
src/ntg/ranking/
outputs/ranking/




### 6ï¸ Churn Risk Modeling
- Inactivity-based churn labeling
- Supervised churn probability estimation
- Evaluation & calibration reports

**Location**
src/ntg/churn/
outputs/churn/



### 7ï¸ Evaluation & Calibration
- Metrics reported as versioned JSON artifacts
- Calibration curves & Expected Calibration Error (ECE)
- Schema validation for downstream consumers

**Location**
src/ntg/evaluation/
outputs/reports/




##  Configuration & Reproducibility

NTG is **fully config-driven**.

configs/
â”œâ”€â”€ base.yaml
â”œâ”€â”€ dev.yaml
â””â”€â”€ prod.yaml


- Environment-specific overrides
- Deterministic reruns
- CI uses dev config for stability

---

##  Command-Line Interface

A real CLI is provided to mirror internal tooling.

### Run everything
```bash
poetry run ntg run-all
Run step-by-step
poetry run ntg build-dataset
poetry run ntg build-features
poetry run ntg build-graph
poetry run ntg rank
poetry run ntg score-users
Use a specific config
poetry run ntg --config configs/dev.yaml run-all
Testing & CI
Test Coverage
Unit tests: schemas, metrics, leakage checks

Integration tests: pipeline smoke tests

poetry run pytest
CI Signals
Fast unit tests on PRs

Nightly end-to-end pipeline on synthetic data

Deterministic failures for regressions

Repository Structure
.
â”œâ”€â”€ configs/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ features/
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ churn/
â”‚   â””â”€â”€ reports/
â”œâ”€â”€ reports/figures/
â”œâ”€â”€ src/ntg/
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ logging.py
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ churn/
â”‚   â””â”€â”€ evaluation/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â””â”€â”€ README.md

Outputs

After a successful run:

data/features/*.parquet â€“ engineered features

outputs/graph/*.parquet â€“ similarity graph

outputs/embeddings/*.parquet â€“ embeddings

outputs/churn/*.parquet â€“ churn scores

outputs/reports/*.json â€“ metrics & calibration

reports/figures/ â€“ diagnostic plots

Dataset Note
MovieLens is used only as a public proxy.

This project is not about movie ratings.

It is about:

Personalization system design

Retention modeling patterns

Decision-oriented ML pipelines

All architectural choices generalize directly to real production event data.